{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recommend that you use PyArrow to load your .parquet files. \n",
    "\n",
    "https://arrow.apache.org/docs/python/parquet.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowIOError",
     "evalue": "Failed to open local file: data/valid.parquet , error: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowIOError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-6c502519d735>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#Using PyArrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/train.parquet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf_valid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/valid.parquet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pyarrow/parquet.py\u001b[0m in \u001b[0;36mread_table\u001b[0;34m(source, columns, nthreads, metadata, use_pandas_metadata)\u001b[0m\n\u001b[1;32m    819\u001b[0m                                    metadata=metadata)\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m     \u001b[0mpf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParquetFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m     return pf.read(columns=columns, nthreads=nthreads,\n\u001b[1;32m    823\u001b[0m                    use_pandas_metadata=use_pandas_metadata)\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pyarrow/parquet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, source, metadata, common_metadata)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommon_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParquetReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommon_metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_parquet.pyx\u001b[0m in \u001b[0;36mpyarrow._parquet.ParquetReader.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mio.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.get_reader\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mio.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.memory_map\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mio.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.MemoryMappedFile._open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32merror.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowIOError\u001b[0m: Failed to open local file: data/valid.parquet , error: No such file or directory"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "#Using PyArrow\n",
    "df_train=pq.read_table(\"data/train.parquet\")\n",
    "df_valid=pq.read_table(\"data/valid.parquet\")\n",
    "\n",
    "df_train=df_train.to_pandas()\n",
    "df_valid=df_valid.to_pandas()\n",
    "#df_train.head()\n",
    "#df_valid.head()\n",
    "\n",
    "df_valid[target]=df_valid[target].replace(\"Wallet\",int(0) )\n",
    "df_valid[target]=df_valid[target].replace(\"Free Trial\",int(1) )\n",
    "df_valid[target]=df_valid[target].replace(\"Retail\",int(2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative Method: Make your own Spark Cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many rows are in each file?\n",
      "129550\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "Index([u'sce_region_id', u'fulfillment_end_utc_dt_id',\n",
      "       u'cur_subscription_renewal_type',\n",
      "       u'subscription_sku_entitlement_period', u'subscription_sku_method',\n",
      "       u'psn_tenure_month', u'total_playtime_seconds_91',\n",
      "       u'total_playtime_seconds_31', u'total_playtime_seconds_14',\n",
      "       u'total_playtime_seconds_7', u'total_igc_playtime_seconds_91',\n",
      "       u'total_igc_playtime_seconds_31', u'total_igc_playtime_seconds_14',\n",
      "       u'total_igc_playtime_seconds_7', u'playdays_91', u'playdays_31',\n",
      "       u'playdays_14', u'playdays_7', u'total_online_seconds_91',\n",
      "       u'total_online_seconds_31', u'total_online_seconds_14',\n",
      "       u'total_online_seconds_7', u'online_playdays_91', u'stacked',\n",
      "       u'ar_status', u'ad_status', u'cc_record_type', u'hist_lapsed',\n",
      "       u'hist_retained', u'hist_reclaimed', u'store_spend_91',\n",
      "       u'accumulated_igc_titles', u'purchased_discounted_titles',\n",
      "       u'wallet_balance', u'cur_entitlement_days', u'payment_method_id',\n",
      "       u'subscription_sku_type_id', u'continuous_subscriptions',\n",
      "       u'subscription_number', u'subscription_days_ltd_free',\n",
      "       u'subscription_days_ltd', u'subscription_value_ltd', u'ar_off_count',\n",
      "       u'renewed_recently'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "sc = SparkContext.getOrCreate()\n",
    "from pyspark.sql import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train=spark.read.parquet(\"data/train.parquet\")\n",
    "valid=spark.read.parquet(\"data/valid.parquet\")\n",
    "evaluation=spark.read.parquet(\"data/eval.parquet\") #Students will not have access to this file.\n",
    "evaluation_noTarget=spark.read.parquet(\"data/eval_noTarget.parquet\")\n",
    "\n",
    "print (\"How many rows are in each file?\")\n",
    "print (train.count() )\n",
    "print (valid.count() )\n",
    "print (evaluation.count() )\n",
    "print (evaluation_noTarget.count() )\n",
    "\n",
    "#Turn into a Pandas DataFrame Iff you have Spark installed on your system\n",
    "valid=valid.toPandas()\n",
    "\n",
    "validCols=valid.columns\n",
    "print (validCols)\n",
    "\n",
    "\n",
    "target=\"subscription_sku_method\"\n",
    "valid[target]=valid[target].replace(\"Wallet\",int(0) )\n",
    "valid[target]=valid[target].replace(\"Free Trial\",int(1) )\n",
    "valid[target]=valid[target].replace(\"Retail\",int(2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a naive model, in which we predict the Users will always renew their \n",
    "subscription via their wallet funds!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   actual  prediction\n",
      "0       0         0.0\n",
      "1       0         0.0\n",
      "2       0         0.0\n",
      "3       0         0.0\n",
      "4       1         0.0\n"
     ]
    }
   ],
   "source": [
    "naiveModel=np.zeros(len(valid[target]) ) #Always predict \"Wallet\"\n",
    "df_naiveModel=np.zeros(len(df_valid[target]) )\n",
    "\n",
    "#PyArrow Version\n",
    "compareY=pd.DataFrame({\"actual\": df_valid[target] , \"prediction\":df_naiveModel})\n",
    "\n",
    "#Spark Version of DataFrames\n",
    "compareY=pd.DataFrame({\"actual\": valid[target] , \"prediction\":naiveModel})\n",
    "\n",
    "print (compareY.head() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using F1, or some other Classification Metric, we will be using \n",
    "our own cost function: How much does this misclassification cost Sony in \n",
    "either lost revenue, advertising, and coding times.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's Build a Cost Function Specific to this use-case!\n",
      "Cost function: $4297.25\n"
     ]
    }
   ],
   "source": [
    "print (\"Let's Build a Cost Function Specific to this use-case!\")\n",
    "\n",
    "\n",
    "def COST(row):\n",
    "    \"\"\" Input the column names of your target variable \n",
    "    (actualCol) and the predicted value of the target (\n",
    "    predCol) to compute this cost function.\"\"\"\n",
    "    actualCol=\"actual\"\n",
    "    predCol=\"prediction\"\n",
    "    if row[actualCol]==row[predCol]:\n",
    "        return 0.0#If the prediction is correct, no problem.\n",
    "    else:\n",
    "        if row[predCol] == 0.0: #Prediction: User paid via Wallet\n",
    "            if row[actualCol]==1.0: #Actual: User had a Free Trial\n",
    "                return 12.0 # Strong negative reaction. Should have known!\n",
    "            if row[actualCol]==2.0: #User went to the store and purchased\n",
    "                return 0.25 #Little difference to Sony's bottom line. Minimal cost.\n",
    "            \n",
    "        if row[predCol] == 1.0: #Prediction: User has a Free Trial\n",
    "            if row[actualCol]==0.0: #Actual: User paid via Wallet\n",
    "                return 5.0 #User becomes annoyed at ads to renew their non-existent free trial\n",
    "            if row[actualCol]==2.0: #Actual: User went to the store and purchased\n",
    "                return 5.0 #User becomes annoyed at ads to renew their non-existent free trial\n",
    "            \n",
    "        if row[predCol] == 2.0: #Prediction: User purchases subscription via retail\n",
    "            if row[actualCol]==0.0: #Actual: User paid via Wallet\n",
    "                return 0.25 #Little difference to Sony's bottom line.\n",
    "            if row[actualCol]==1.0: #Actual: User has a free trial\n",
    "                return 12.0 # Large cost to Playstation, as they do not renew.\n",
    "\n",
    "\n",
    "cost = compareY.apply( COST, axis=1).sum()\n",
    "print (\"Cost function: $%.2f\" %cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
